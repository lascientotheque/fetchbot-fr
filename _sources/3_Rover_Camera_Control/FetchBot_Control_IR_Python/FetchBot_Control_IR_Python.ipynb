{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76ead129",
   "metadata": {},
   "source": [
    "# Contrôle du FetchBot et reconnaissance d'images avec Python\n",
    "\n",
    "**Objectif:** Faire déplacer le FetchBot avec Python en utilisant la reconnaissance d'images.\n",
    "\n",
    "|||\n",
    ":--- | :--- |\n",
    "|Âge |14 à 18 ans|\n",
    "|Notions abordées|Intelligence artificielle, classification d’images, robotique, programmation avec Scratch, condition, boucle.|\n",
    "| Durée| 4 heures|\n",
    "| Dispositif pédagogiques| Par groupe de 2|\n",
    "| Matériel| Un FetchBot et un laptop/tablette par groupe de 2, avec connexion à Internet|\n",
    "| Prérequis| 1. Connaissances de bases de Python (voir Activité 3 - Reconnaissance d'images avec Python)<br> 2. Avoir pris en main le Raspberry Pi, et savoir s'y connecter avec VNC viewer (voir [Raspberry Pi: Prise en main et préparation](Raspberry_Pi))<br> 3. Avoir construit le FetchBot (voir [Activité 4 - Construction du rover](Rover_Building))<br> 4. Avoir programmé le FetchBot pour le faire se déplacer (voir [Activité 6 - Contrôle du FetchBot avec Python](FetchBot_Control_Python))|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f4d45",
   "metadata": {},
   "source": [
    "## Aperçu\n",
    "\n",
    "Dans cette activité, tu vas programmer le FetchBot pour le faire explorer un terrain et retrouver un objet. On utilisera comme exemple ici la recherche d'un tube sur un sol martien, comme ce que devra faire le rover Fetch sur mars. Tu utiliseras la reconnaissance d'images pour contrôler ce que fais le rover: Faire avancer le robot lorsque le terrain est dégagé, le faire tourner lorsqu'il rencontre un obstacle, et le faire s'arrêter lorsqu'il trouve le tube. \n",
    "\n",
    "<img src=\"images/Fetchbot_Moving.gif\" width=\"600\"/> \n",
    "\n",
    "L'activité se compose de trois parties principales: \n",
    "\n",
    "* Créer un modèle de reconnaissance d'images capable de détecter 3 types de classes: le sol dégagé, les obstacles, et les tubes\n",
    "* Utiliser le modèle de reconnaissance d'images dans un programme Scratch pour faire dire au sprite de rover la classe détectée (comme dans l'activité 2)\n",
    "* Rajouter à ce programme Scratch l'envoi de commandes au rover en fonction de la classe détectée.\n",
    "\n",
    "La [vidéo de ce lien](https://www.youtube.com/watch?v=52H9oy993JY) te donne un aperçu de la réalisation de ces activités.\n",
    "\n",
    "```{note}\n",
    "L'activité peut être adaptée pour la recherche d'autres objets (crayon, pièce de légo, ...) et sur d'autres types de terrains, par exemple le sol de ta classe, ou même un terrain en extérieur. \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dece563",
   "metadata": {},
   "source": [
    "## Préparation\n",
    "\n",
    "Ton [rover est construit](Rover_Building), et tu y es [connecté avec VNC viewer](Raspberry_Pi) depuis un ordinateur ou une tablette. \n",
    "\n",
    "Il te faudra ensuite choisir un objet que le rover devra retrouver, et délimiter une zone dans laquelle le rover devra rechercher cet objet. Pour l'objet, tu peux choisir un tube, un crayon, une pièce de légo, ou autre. Pour la zone de recherche, tu peux imprimer un [sol martien](https://www.esa.int/ESA_Multimedia/Images/2019/12/Mars_terrain) au format A0 ou sous forme de tapis, ou sinon délimiter une zone avec du ruban adhésif. Tu pourras ajouter dans la zone des obstacles à éviter (cailloux, boites, ou autre).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a97c94",
   "metadata": {},
   "source": [
    "## Création du modèle de reconnaissance d'images\n",
    "\n",
    "La création du modèle suit le même principe que celui décrit dans [l'activité 1 - Reconnaissance d'images avec la Teachable Machine](Image_Recognition). Il te faudra ici prendre des exemples d'images pour trois classes: \n",
    "\n",
    "* le sol dégagé: classe 'sol'. Les exemples peuvent inclure ici toute partie de la zone où le robot peut avancer, c'est à dire qui ne contient ni obstacle, ni tube. \n",
    "* les obstacles: classe 'obstacle'. Les exemples peuvent inclure ici toute partie de la zone où le robot est face à un obstacle, comme un bord, un autre robot, ou des objets à éviter comme des cailloux.\n",
    "* le tube à retrouver: classe 'tube'. Les exemples peuvent inlcure ici toute partie de la zone où le robot est devant un tube. \n",
    "\n",
    "Ouvre un projet d'images dans la Teachable Machine, et crée trois catégories 'Sol', 'Obstacle', et 'Tube'.\n",
    "\n",
    "<img src=\"images/TM_Classes.jpg\" width=\"800\"/> \n",
    "\n",
    "\n",
    "Pour chaque classe, il est en général suffisant de prendre une vingtaine d'exemples. Essaye de varier au maximum les exemples que tu prends (angle ou distance par rapport à un obstacle ou un tube, luminosité, reflet sur le sol, etc...).\n",
    "\n",
    "La [vidéo ici](https://www.youtube.com/watch?v=52H9oy993JY) (partie 'Training', de 1'13 à 3'53) te montre comment faire cela en pratique. \n",
    "\n",
    "Après avoir pris une vingtaine d'exemples pour chaque classe, entraîne le modèle. Tu peux ensuite tester si le modèle reconnaît correctement les trois classes. L'interface devrait de la Teachable Machine devrait ressembler à ceci:\n",
    "\n",
    "<img src=\"images/TM_Examples.jpg\" width=\"800\"/> \n",
    "\n",
    "Ici, un tube est devant la caméra, et le modèle reconnaît correctement (classe 'Tube' détectée à 100%). \n",
    "\n",
    "```{note}\n",
    "Il est plus facile d'être deux pour prendre les exemples d'images des trois classes: un pour déplacer le rover dans la zone, et l'autre pour prendre les photos sur la Teachable Machine. \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da988b87",
   "metadata": {},
   "source": [
    "## Reconnaissance d'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5689cf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je reconnais la classe 'Other'\n",
      "Je reconnais la classe 'Other'\n",
      "Je reconnais la classe 'Forward'\n",
      "Je reconnais la classe 'Forward'\n",
      "Je reconnais la classe 'Other'\n",
      "Je reconnais la classe 'Other'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2y/mv3z1v0945b60_l2bzjwpzj80000gn/T/ipykernel_83580/618073387.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Take image from the camera\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mpicture_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_picture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Predict image class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Scientotheque/fiches-ia/ai-rover-fr/03_Image_Recognition_Python/myfunctions.py\u001b[0m in \u001b[0;36mtake_picture\u001b[0;34m(camera_object, input_image_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtake_picture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_image_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mreturn_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpicture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamera_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpicture_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpicture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Necessary import\n",
    "import cv2 # cv2 is used to take image from the camera\n",
    "import myfunctions # myfunctions helps for taking picture and making predictions\n",
    "import matplotlib.pyplot as plt # matplotlib is used to deal with images\n",
    "from PIL import Image # PIL is used to deal with images\n",
    "import time # time is used for making the computer wait\n",
    "\n",
    "# Get camera object\n",
    "camera_object = cv2.VideoCapture(0)\n",
    "camera_object.set(cv2.CAP_PROP_BUFFERSIZE, 3)\n",
    "\n",
    "# Initialize model\n",
    "interpreter = myfunctions.initialize_model(model_path='model.tflite')\n",
    "\n",
    "# Infinite loop\n",
    "while True:\n",
    "    \n",
    "    # Wait for one second\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Take image from the camera\n",
    "    picture_rgb = myfunctions.take_picture(camera_object)\n",
    "    \n",
    "    # Predict image class\n",
    "    prediction, probability = myfunctions.model_prediction(interpreter, picture_rgb)\n",
    "    \n",
    "    # If prediction is class 0, class is 'Tube'\n",
    "    if prediction == 0:\n",
    "        \n",
    "        print(\"Je reconnais la classe 'Tube'\")\n",
    "        \n",
    "    # If prediction is class 1, class is 'Autre'\n",
    "    if prediction == 1:\n",
    "        \n",
    "        print(\"Je reconnais la classe 'Other'\")\n",
    "        \n",
    "        # If prediction is class 2, class is 'Bord'\n",
    "    if prediction == 2:\n",
    "        \n",
    "        print(\"Je reconnais la classe 'Bord'\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68083131",
   "metadata": {},
   "source": [
    "## Contrôle du rover avec la reconnaissance d'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0837bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary import\n",
    "import cv2 # cv2 is used to take image from the camera\n",
    "import myfunctions # myfunctions helps for taking picture and making predictions\n",
    "import matplotlib.pyplot as plt # matplotlib is used to deal with images\n",
    "from PIL import Image # PIL is used to deal with images\n",
    "import time # time is used for making the computer wait\n",
    "\n",
    "# Get camera object\n",
    "camera_object = cv2.VideoCapture(0)\n",
    "camera_object.set(cv2.CAP_PROP_BUFFERSIZE, 3)\n",
    "\n",
    "# Initialize model\n",
    "interpreter = myfunctions.initialize_model(model_path='model.tflite')\n",
    "\n",
    "# Infinite loop\n",
    "while True:\n",
    "    \n",
    "    # Wait for one second\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Take image from the camera\n",
    "    picture_rgb = myfunctions.take_picture(camera_object)\n",
    "    \n",
    "    # Predict image class\n",
    "    prediction, probability = myfunctions.model_prediction(interpreter, picture_rgb)\n",
    "    \n",
    "    # If prediction is class 0, class is 'Tube'\n",
    "    if prediction == 0:\n",
    "        \n",
    "        print(\"Je reconnais la classe 'Tube'\")\n",
    "        \n",
    "    # If prediction is class 1, class is 'Autre'\n",
    "    if prediction == 1:\n",
    "        \n",
    "        print(\"Je reconnais la classe 'Other'\")\n",
    "        \n",
    "        # If prediction is class 2, class is 'Bord'\n",
    "    if prediction == 2:\n",
    "        \n",
    "        print(\"Je reconnais la classe 'Bord'\")    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
