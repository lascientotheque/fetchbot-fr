{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f675b064",
   "metadata": {},
   "source": [
    "# Contrôle du FetchBot et reconnaissance d'images avec Scratch\n",
    "\n",
    "**Objectif:** Faire déplacer le FetchBot avec Scratch en utilisant la reconnaissance d'images.\n",
    "\n",
    "|||\n",
    ":--- | :--- |\n",
    "|Âge |10 à 14 ans|\n",
    "|Notions abordées|Intelligence artificielle, classification d’images, robotique, programmation avec Scratch, condition, boucle.|\n",
    "| Durée| 4 heures|\n",
    "| Dispositif pédagogiques| Par groupe de 2|\n",
    "| Matériel| Un FetchBot et un laptop/tablette par groupe de 2, avec connexion à Internet|\n",
    "| Prérequis| 1. Reconnaissance d'images avec Scratch (voir [Activité 2 - Reconnaissance d'images avec Scratch](Image_Recognition_Scratch))<br> 2. Avoir pris en main le Raspberry Pi, et savoir s'y connecter avec VNC viewer (voir [Raspberry Pi: Prise en main et préparation](Raspberry_Pi))<br> 3. Avoir construit le FetchBot (voir [Activité 4 - Construction du rover](Rover_Building))<br> 4. Avoir programmé le FetchBot pour le faire se déplacer (voir [Activité 5 - Contrôle du FetchBot avec Scratch](FetchBot_Control_Scratch))|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9039a",
   "metadata": {},
   "source": [
    "## Aperçu\n",
    "\n",
    "Dans cette activité, tu vas programmer le FetchBot pour le faire explorer un terrain et retrouver un objet. On utilisera comme exemple ici la recherche d'un tube sur un sol martien, comme ce que devra faire le rover Fetch sur mars. Tu utiliseras la reconnaissance d'images pour contrôler ce que fais le rover: Faire avancer le robot lorsque le terrain est dégagé, le faire tourner lorsqu'il rencontre un obstacle, et le faire s'arrêter lorsqu'il trouve le tube. \n",
    "\n",
    "<img src=\"images/Fetchbot_Moving.gif\" width=\"600\"/> \n",
    "\n",
    "L'activité se compose de trois parties principales: \n",
    "\n",
    "* Créer un modèle de reconnaissance d'images capable de détecter 3 types de classes: le sol dégagé, les obstacles, et les tubes\n",
    "* Utiliser le modèle de reconnaissance d'images dans un programme Scratch pour faire dire au sprite de rover la classe détectée (comme dans l'activité 2)\n",
    "* Rajouter à ce programme Scratch l'envoi de commandes au rover en fonction de la classe détectée.\n",
    "\n",
    "La [vidéo de ce lien](https://www.youtube.com/watch?v=r4aqZdWUQGM) te donne un aperçu de la réalisation de ces activités.\n",
    "\n",
    "```{note}\n",
    "L'activité peut être adaptée pour la recherche d'autres objets (crayon, pièce de légo, ...) et sur d'autres types de terrains, par exemple le sol de ta classe, ou même un terrain en extérieur. \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4f1a06",
   "metadata": {},
   "source": [
    "## Préparation\n",
    "\n",
    "Ton [rover est construit](Rover_Building), et tu y es [connecté avec VNC viewer](Raspberry_Pi) depuis un ordinateur ou une tablette. \n",
    "\n",
    "Il te faudra ensuite choisir un objet que le rover devra retrouver, et délimiter une zone dans laquelle le rover devra rechercher cet objet. Pour l'objet, tu peux choisir un tube, un crayon, une pièce de légo, ou autre. Pour la zone de recherche, tu peux imprimer un [sol martien](https://www.esa.int/ESA_Multimedia/Images/2019/12/Mars_terrain) au format A0 ou sous forme de tapis, ou sinon délimiter une zone avec du ruban adhésif. Tu pourras ajouter dans la zone des obstacles à éviter (cailloux, boites, ou autre).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f0a099",
   "metadata": {},
   "source": [
    "## Création du modèle de reconnaissance d'images\n",
    "\n",
    "La création du modèle suit le même principe que celui décrit dans [l'activité 1 - Reconnaissance d'images avec la Teachable Machine](Image_Recognition). Il te faudra ici prendre des exemples d'images pour trois classes: \n",
    "\n",
    "* le sol dégagé: classe 'sol'. Les exemples peuvent inclure ici toute partie de la zone où le robot peut avancer, c'est à dire qui ne contient ni obstacle, ni tube. \n",
    "* les obstacles: classe 'obstacle'. Les exemples peuvent inclure ici toute partie de la zone où le robot est face à un obstacle, comme un bord, un autre robot, ou des objets à éviter comme des cailloux.\n",
    "* le tube à retrouver: classe 'tube'. Les exemples peuvent inlcure ici toute partie de la zone où le robot est devant un tube. \n",
    "\n",
    "Ouvre un projet d'images dans la Teachable Machine, et crée trois catégories 'Sol', 'Obstacle', et 'Tube'.\n",
    "\n",
    "<img src=\"images/TM_Classes.jpg\" width=\"800\"/> \n",
    "\n",
    "\n",
    "Pour chaque classe, il est en général suffisant de prendre une vingtaine d'exemples. Essaye de varier au maximum les exemples que tu prends (angle ou distance par rapport à un obstacle ou un tube, luminosité, reflet sur le sol, etc...).\n",
    "\n",
    "La [vidéo ici](https://www.youtube.com/watch?v=r4aqZdWUQGM) (partie 'Training', de 1'30 à 4'50) te montre comment faire cela en pratique. \n",
    "\n",
    "Après avoir pris une vingtaine d'exemples pour chaque classe, entraîne le modèle. Tu peux ensuite tester si le modèle reconnaît correctement les trois classes. L'interface devrait de la Teachable Machine devrait ressembler à ceci:\n",
    "\n",
    "<img src=\"images/TM_Examples.jpg\" width=\"800\"/> \n",
    "\n",
    "Ici, un tube est devant la caméra, et le modèle reconnaît correctement (classe 'Tube' détectée à 100%). \n",
    "\n",
    "```{note}\n",
    "Il est plus facile d'être deux pour prendre les exemples d'images des trois classes: un pour déplacer le rover dans la zone, et l'autre pour prendre les photos sur la Teachable Machine. \n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fd9dbf",
   "metadata": {},
   "source": [
    "## Faire dire au sprite ce que le modèle reconnaît\n",
    "\n",
    "Tu peux maintenant utiliser le modèle dans Adacraft et faire dire au sprite ce qu'il reconnaît. Le principe est le même que celui décrit dans [l'activité 2](IR_Scratch). Tu as ici trois classes, donc une troisième condition à ajouter dans le logigramme:\n",
    "\n",
    "<img src=\"images/localisation/Algorithm_1_ImageRecognition.jpg\" width=\"500\"/> \n",
    "\n",
    "Voici le programme à obtenir:\n",
    "\n",
    "<img src=\"images/localisation/Adacraft_1_IR_Blocks.jpg\"  width=\"600\"/> \n",
    "\n",
    "```{note}\n",
    "Attention: Dans le bloc \"Sélectionner et initialiser le modèle dont l'URL est ...\", c'est l'URL du modèle que tu as créé qu'il faut mettre!\n",
    "```\n",
    "\n",
    "Le programme se trouve dans le répertoire `3_Rover_Camera_Control/FetchBot_Control_IR_Scratch/Adacraft_Scratch` et s'appelle `FetchBot_IR_Scratch.sb3`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef35b7a8",
   "metadata": {},
   "source": [
    "## Contrôle du rover avec la reconnaissance d'images\n",
    "\n",
    "Il ne te reste plus qu'à programmer comment contrôler rover en fonction de que la caméra détecte. Modifie le programme pour \n",
    "\n",
    "* Faire avancer le rover si la classe détectée est le sol\n",
    "* Faire tourner le rover à gauche si la classe détectée est un obstacle.\n",
    "\n",
    "Quel est le logigramme de ce programme?\n",
    "\n",
    "Le contrôle du rover utilise l'extension CloudLink comme vu dans [l'activité 5](FetchBot_Control_Scratch). Voici le programme avec l'ajout des commandes de contrôle:\n",
    "\n",
    "<img src=\"images/localisation/Adacraft_2_Control_IR_Blocks.jpg\"  width=\"600\"/> \n",
    "\n",
    "Le programme se trouve dans le répertoire `3_Rover_Camera_Control/FetchBot_Control_IR_Scratch/Adacraft_Scratch` et s'appelle `FetchBot_Control_IR_Scratch.sb3`.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31adf2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
