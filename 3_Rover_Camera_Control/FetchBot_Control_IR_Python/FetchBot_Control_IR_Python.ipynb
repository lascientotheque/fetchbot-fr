{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76ead129",
   "metadata": {},
   "source": [
    "# Contrôle du FetchBot et reconnaissance d'images avec Python\n",
    "\n",
    "**Objectif:** Faire déplacer le FetchBot avec Python.\n",
    "\n",
    "|||\n",
    ":--- | :--- |\n",
    "|Âge |14 à 18 ans|\n",
    "|Notions abordées|Robotique, programmation avec Python, condition, boucle.|\n",
    "| Durée| 4 heures|\n",
    "| Dispositif pédagogiques| Par groupe de 2|\n",
    "| Matériel| Un FetchBot, Un laptop/tablette par groupe de 2, avec connexion à Internet|\n",
    "| Prérequis| 1. Connaissances de bases de Python (voir Activité 2 - Reconnaissance d'images avec Python)<br> 2. Avoir construit le FetchBot et s'y être connecté avec VNC viewer (voir Activité 4 - Construction du rover)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da988b87",
   "metadata": {},
   "source": [
    "## Reconnaissance d'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5689cf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je reconnais la classe 'Other'\n",
      "Je reconnais la classe 'Other'\n",
      "Je reconnais la classe 'Forward'\n",
      "Je reconnais la classe 'Forward'\n",
      "Je reconnais la classe 'Other'\n",
      "Je reconnais la classe 'Other'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2y/mv3z1v0945b60_l2bzjwpzj80000gn/T/ipykernel_83580/618073387.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Take image from the camera\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mpicture_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_picture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Predict image class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Scientotheque/fiches-ia/ai-rover-fr/03_Image_Recognition_Python/myfunctions.py\u001b[0m in \u001b[0;36mtake_picture\u001b[0;34m(camera_object, input_image_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtake_picture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_image_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mreturn_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpicture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamera_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpicture_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpicture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Necessary import\n",
    "import cv2 # cv2 is used to take image from the camera\n",
    "import myfunctions # myfunctions helps for taking picture and making predictions\n",
    "import matplotlib.pyplot as plt # matplotlib is used to deal with images\n",
    "from PIL import Image # PIL is used to deal with images\n",
    "import time # time is used for making the computer wait\n",
    "\n",
    "# Get camera object\n",
    "camera_object = cv2.VideoCapture(0)\n",
    "camera_object.set(cv2.CAP_PROP_BUFFERSIZE, 3)\n",
    "\n",
    "# Initialize model\n",
    "interpreter = myfunctions.initialize_model(model_path='model.tflite')\n",
    "\n",
    "# Infinite loop\n",
    "while True:\n",
    "    \n",
    "    # Wait for one second\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Take image from the camera\n",
    "    picture_rgb = myfunctions.take_picture(camera_object)\n",
    "    \n",
    "    # Predict image class\n",
    "    prediction, probability = myfunctions.model_prediction(interpreter, picture_rgb)\n",
    "    \n",
    "    # If prediction is class 0, class is 'Tube'\n",
    "    if prediction == 0:\n",
    "        \n",
    "        print(\"Je reconnais la classe 'Tube'\")\n",
    "        \n",
    "    # If prediction is class 1, class is 'Autre'\n",
    "    if prediction == 1:\n",
    "        \n",
    "        print(\"Je reconnais la classe 'Other'\")\n",
    "        \n",
    "        # If prediction is class 2, class is 'Bord'\n",
    "    if prediction == 2:\n",
    "        \n",
    "        print(\"Je reconnais la classe 'Bord'\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaebc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release camera\n",
    "camera_object.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68083131",
   "metadata": {},
   "source": [
    "## Contrôle le rover avec la reconnaissance d'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0837bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary import\n",
    "import cv2 # cv2 is used to take image from the camera\n",
    "import myfunctions # myfunctions helps for taking picture and making predictions\n",
    "import matplotlib.pyplot as plt # matplotlib is used to deal with images\n",
    "from PIL import Image # PIL is used to deal with images\n",
    "import time # time is used for making the computer wait\n",
    "\n",
    "# Get camera object\n",
    "camera_object = cv2.VideoCapture(0)\n",
    "camera_object.set(cv2.CAP_PROP_BUFFERSIZE, 3)\n",
    "\n",
    "# Initialize model\n",
    "interpreter = myfunctions.initialize_model(model_path='model.tflite')\n",
    "\n",
    "# Infinite loop\n",
    "while True:\n",
    "    \n",
    "    # Wait for one second\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Take image from the camera\n",
    "    picture_rgb = myfunctions.take_picture(camera_object)\n",
    "    \n",
    "    # Predict image class\n",
    "    prediction, probability = myfunctions.model_prediction(interpreter, picture_rgb)\n",
    "    \n",
    "    # If prediction is class 0, class is 'Tube'\n",
    "    if prediction == 0:\n",
    "        \n",
    "        print(\"Je reconnais la classe 'Tube'\")\n",
    "        \n",
    "    # If prediction is class 1, class is 'Autre'\n",
    "    if prediction == 1:\n",
    "        \n",
    "        print(\"Je reconnais la classe 'Other'\")\n",
    "        \n",
    "        # If prediction is class 2, class is 'Bord'\n",
    "    if prediction == 2:\n",
    "        \n",
    "        print(\"Je reconnais la classe 'Bord'\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a8ebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release camera\n",
    "camera_object.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a23b2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc3b6770",
   "metadata": {},
   "source": [
    "## Aller plus loin\n",
    "\n",
    "* Ajoute des classes avec des images de flèches vers la droite ou la gauche pour faire tourner la tortue à droite ou à gauche\n",
    "* Fais un classificateur qui utilise l'image de tube sur sol martien, et pour faire avancer la tortue si aucun tube n'est détecté, et fais s'arrêter la tortue lorsqu'un tube est détecté\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dff90c",
   "metadata": {},
   "source": [
    "## Ressources utiles\n",
    "\n",
    "* Documentation pour la tortue Python: https://docs.python.org/fr/3/library/turtle.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a1e831",
   "metadata": {},
   "source": [
    "## Notes sur les objectifs pédagogiques\n",
    "\n",
    "Référentiel FMTTN:\n",
    "\n",
    "1. Lire un algorithme simple\n",
    "2. Écrire un algorithme simple \n",
    "3. Lire un programme simple \n",
    "4. Écrire un programme simple \n",
    "5. Identifier des éléments relatifs à la programmation et aux logigrammes.|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
